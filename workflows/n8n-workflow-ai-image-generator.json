{
  "name": "üé® AI Image Generator - v7 (COMPLETE FIXED)",
  "nodes": [
    {
      "parameters": {
        "public": true,
        "availableInChat": true,
        "agentName": "AI Image Generator",
        "agentDescription": "Chat, analyze images, and generate AI art",
        "options": {
          "allowedOrigins": "*",
          "responseMode": "streaming"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.4,
      "position": [
        -640,
        160
      ],
      "id": "cdd73e3d-870f-4197-85fb-1a9715435bdc",
      "name": "Chat Trigger",
      "webhookId": "db604b2c-9149-41f1-bcc1-b1a5f38a1f3b"
    },
    {
      "parameters": {
        "jsCode": "const attachments = $json.attachments || [];\n\nconst images = attachments\n  .filter(a => {\n    const mime = a.type || a.mimeType || a.contentType || (a.data?.split(';')[0].replace('data:', ''));\n    return mime && mime.startsWith('image/');\n  })\n  .map(a => ({\n    name: a.name,\n    mimeType: a.type || a.mimeType,\n    data: a.data\n  }));\n\nreturn [{\n  json: {\n    ...$json,\n    images,\n    imageCount: images.length,\n    hasImages: images.length > 0\n  }\n}];"
      },
      "id": "26a44de1-6a68-4994-9534-8b41677aca7c",
      "name": "Check Attachments",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -432,
        160
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose"
          },
          "conditions": [
            {
              "id": "c1",
              "leftValue": "={{ $json.hasImages }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "true"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "92a3990b-d44f-490c-99df-d3a7419abb84",
      "name": "Has Images?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -240,
        160
      ]
    },
    {
      "parameters": {
        "jsCode": "const images = $json.images || [];\nconst chatInput = $json.chatInput || 'What do you see in this image?';\n\nconst prompt = `[User attached ${images.length} image(s)]\\n\\n${chatInput}\\n\\nPlease analyze the image(s) and describe what you see in detail.`;\n\nconst base64Images = images.map(img => {\n  let base64 = img.data;\n  if (base64.includes('base64,')) {\n    base64 = base64.split('base64,')[1];\n  }\n  return base64;\n});\n\nconsole.log('Vision request:', {\n  prompt: prompt.substring(0, 100),\n  imageCount: base64Images.length,\n  firstImageLength: base64Images[0]?.length || 0\n});\n\nreturn [{\n  json: {\n    model: 'llava',\n    prompt: prompt,\n    images: base64Images,\n    stream: false\n  }\n}];"
      },
      "id": "35511fc0-83fc-468c-b948-2bcd04e6d648",
      "name": "Prepare Vision",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -32,
        48
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.50.56:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json) }}",
        "options": {
          "timeout": 120000
        }
      },
      "id": "da88fe43-348b-4c46-a432-b9460235eebd",
      "name": "Llava Direct API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        144,
        -64
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "1",
              "name": "text",
              "type": "string",
              "value": "={{ $json.response }}"
            }
          ]
        },
        "options": {}
      },
      "id": "0b706603-4809-4bd1-813d-de196c0d6105",
      "name": "Format Vision Output",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        336,
        -80
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose"
          },
          "conditions": [
            {
              "id": "c1",
              "leftValue": "={{ $json.chatInput.toLowerCase() }}",
              "rightValue": "image",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "15e3b423-92f5-4037-8720-396e51796e12",
      "name": "Contains 'image'?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -464,
        480
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are an expert Stable Diffusion prompt engineer.\n\nUser request: {{ $json.chatInput }}\n\nIMPORTANT: Along with your JSON response, you must preserve the original user request.\nThe original request will be needed later in the workflow.\n\nCRITICAL RULES:\n1. For photorealistic: DO NOT add \"colorful background\", \"vibrant colors\", \"studio photography\", or \"geometric patterns\"\n2. Keep it NATURAL - describe only the subject with natural lighting\n3. For cartoon: use \"cartoon style illustration\", vibrant colors, bold outlines\n4. For logos: use \"professional logo design featuring letters [LETTERS]\"\n\nSTYLE DETECTION:\n- If contains \"cartoon\" or \"anime\" ‚Üí CARTOON style\n- If contains \"logo\" or is 2-5 letters ‚Üí LOGO style  \n- Otherwise ‚Üí PHOTOREALISTIC (default)\n\nPHOTOREALISTIC TEMPLATE:\n[SUBJECT], natural lighting, realistic, detailed, sharp focus\n\nCARTOON TEMPLATE:\ncartoon style illustration of [SUBJECT], vibrant colors, bold outlines, animated style\n\nReturn ONLY valid JSON:\n{\n  \"positive\": \"prompt here\",\n  \"negative\": \"blurry, low quality, cartoon, anime, illustration, distorted\"\n}"
      },
      "id": "c9e643fa-1748-4894-8be6-992d9e414f8c",
      "name": "AI Engineer",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        96,
        160
      ]
    },
    {
      "parameters": {
        "model": "qwen2.5:latest",
        "options": {}
      },
      "id": "aa2df7be-ac10-4d63-ad80-b2a1688cc65a",
      "name": "Ollama Engineer",
      "type": "@n8n/n8n-nodes-langchain.lmOllama",
      "typeVersion": 1,
      "position": [
        176,
        352
      ],
      "credentials": {
        "ollamaApi": {
          "id": "xHuYe0MDGOs9IpBW",
          "name": "Local Ollama service"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Get AI response from current input\nconst aiResponse = $input.item.json.text || $input.item.json.response || '';\n\n// Get original input from \"Save Original Input\" node by name\nlet originalInput = '';\ntry {\n  const saveNode = $('Save Original Input');\n  if (saveNode && saveNode.first()) {\n    const savedData = saveNode.first().json;\n    originalInput = savedData.originalChatInput || savedData.chatInput || '';\n    console.log('‚úÖ Got from Save Original Input:', originalInput.substring(0, 80));\n  }\n} catch(e) {\n  console.log('‚ùå Could not access Save Original Input node:', e.message);\n}\n\nconsole.log('üìù Parse Prompts:');\nconsole.log('- Original input:', originalInput || 'NOT FOUND ‚ùå');\n\n// Parse JSON\nlet prompts;\ntry {\n  const jsonText = aiResponse.replace(/```json|```/g, '').trim();\n  prompts = JSON.parse(jsonText);\n  console.log('‚úÖ Parsed JSON');\n} catch(e) {\n  prompts = { positive: 'beautiful image', negative: 'blurry, low quality' };\n}\n\nreturn [{\n  json: {\n    positive: prompts.positive || 'beautiful image',\n    negative: prompts.negative || 'blurry, low quality',\n    chatInput: originalInput\n  }\n}];"
      },
      "id": "d96d8678-c687-4722-87a3-2ff342d6ee99",
      "name": "Parse Prompts",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        432,
        144
      ]
    },
    {
      "parameters": {
        "jsCode": "// ===== GET ORIGINAL USER INPUT (BEFORE AI PROCESSING) =====\nconst comfyModels = $input.item.json;\nlet originalUserInput = '';\n\n// Search through all inputs to find the original chatInput (handle _1 suffix from Merge)\nconst allInputs = $input.all();\nfor (const input of allInputs) {\n  // Check for chatInput with or without _1 suffix\n  const chatInput = input.json.chatInput || input.json.chatInput_1 || input.json.chatInput_2;\n  if (chatInput && chatInput.length > 0) {\n    originalUserInput = chatInput.trim();\n    console.log('‚úÖ Found chatInput:', originalUserInput.substring(0, 80));\n    break;\n  }\n}\n\nconsole.log('üîç Original user input:', originalUserInput || 'NOT FOUND');\n\n// ===== PARSED DATA =====\nconst allCheckpoints = $input.all()\n  .filter(item => item.json.checkpoints || item.json.checkpoints_2)\n  .flatMap(item => item.json.checkpoints || item.json.checkpoints_2);\n\nconst allVaes = $input.all()\n  .filter(item => item.json.vae || item.json.vae_2)\n  .flatMap(item => item.json.vae || item.json.vae_2);\n\nconst allLoras = $input.all()\n  .filter(item => item.json.loras || item.json.loras_2)\n  .flatMap(item => item.json.loras || item.json.loras_2);\n\n// ===== AUTO-DETECT MODELS (FILTER OUT INPAINTING) =====\nconst sdxlModels = allCheckpoints\n  .filter(m => m.toLowerCase().includes('xl'))\n  .filter(m => !m.toLowerCase().includes('inpaint'));\n\nconst sd15Models = allCheckpoints\n  .filter(m => !m.toLowerCase().includes('xl'))\n  .filter(m => !m.toLowerCase().includes('inpaint'));\n\nconst fluxModels = allCheckpoints.filter(m => m.toLowerCase().includes('flux'));\n\n// ===== VAES =====\nconst sd15Vae = allVaes.find(v => v.toLowerCase().includes('ae')) || 'ae.safetensors';\nconst animeVae = allVaes.find(v => v.toLowerCase().includes('wan')) || sd15Vae;\nconst sdxlVae = allVaes.find(v => v.toLowerCase().includes('hyper')) || null;\n\n// ===== FALLBACKS =====\nif (!sd15Models.length) sd15Models.push('dreamshaper_8.safetensors');\nif (!sdxlModels.length) sdxlModels.push('sd_xl_base_1.0.safetensors');\n\nconsole.log('üì¶ Available models:');\nconsole.log('- SD1.5:', sd15Models.slice(0, 3).join(', '));\nconsole.log('- SDXL:', sdxlModels.slice(0, 3).join(', '));\n\n// ===== GET PROMPTS (HANDLE _1 SUFFIX FROM MERGE) =====\nlet positive = '';\nlet negative = '';\n\n// Handle both clean and _1 suffixed field names\nconst positiveField = $input.item.json.positive || $input.item.json.positive_1 || '';\nconst negativeField = $input.item.json.negative || $input.item.json.negative_1 || '';\n\nif (positiveField && positiveField !== 'empty') {\n  positive = positiveField;\n  negative = negativeField || 'blurry, low quality, distorted';\n  console.log('‚úÖ Using engineered prompts from AI Engineer');\n} else if (originalUserInput && originalUserInput.length > 5) {\n  positive = originalUserInput.replace(/^generate\\s+image:\\s*/i, '').trim();\n  negative = 'blurry, low quality, distorted, ugly, bad anatomy';\n  console.log('‚úÖ Using original user input as prompt');\n} else {\n  positive = 'beautiful detailed image, high quality, professional';\n  negative = 'blurry, low quality, distorted';\n  console.log('‚ö†Ô∏è Using fallback prompt');\n}\n\n// Safety check\nif (!positive || positive === 'empty' || positive.length < 3) {\n  positive = 'beautiful detailed image, high quality';\n}\n\nconsole.log('üìù Prompts:');\nconsole.log('- Positive:', positive.substring(0, 80));\nconsole.log('- Negative:', negative.substring(0, 50));\n\n// ===== DEFAULT SETTINGS =====\nlet quality = { steps: 50, cfg: 6.5, sampler: 'dpm_2', scheduler: 'karras' };\nlet dimensions = { width: 512, height: 512, desc: '512x512' };\nlet model = sd15Models[0];\nlet modelType = 'SD1.5';\nlet selectedVae = sd15Vae;\n\n// ===== STYLE DETECTION (USE ORIGINAL INPUT!) =====\nconst lowerOriginal = originalUserInput.toLowerCase();\nconst isCartoon = lowerOriginal.includes('cartoon') || lowerOriginal.includes('anime');\nconst isLogo = lowerOriginal.includes('logo');\nconst isFluxLogo = isLogo && lowerOriginal.includes('flux');\n\n// ===== DIMENSIONS OVERRIDE (CHECK ORIGINAL INPUT!) =====\nif (lowerOriginal.includes('1024')) {\n  dimensions = { width: 1024, height: 1024, desc: '1024x1024' };\n  model = sdxlModels[0];\n  modelType = 'SDXL';\n  quality.steps = 30;\n  quality.cfg = 6.0;\n  console.log('‚úÖ 1024x1024 detected ‚Üí Using SDXL:', model);\n}\nif (lowerOriginal.includes('2048')) {\n  dimensions = { width: 2048, height: 2048, desc: '2048x2048' };\n  model = sdxlModels[0];\n  modelType = 'SDXL';\n  quality.steps = 40;\n  quality.cfg = 5.5;\n  console.log('‚úÖ 2048x2048 detected ‚Üí Using SDXL');\n}\nif (lowerOriginal.includes('portrait') && !lowerOriginal.includes('1024')) {\n  dimensions = { width: 512, height: 768, desc: 'Portrait 512x768' };\n  console.log('‚úÖ Portrait orientation');\n}\nif (lowerOriginal.includes('landscape') && !lowerOriginal.includes('1024')) {\n  dimensions = { width: 768, height: 512, desc: 'Landscape 768x512' };\n  console.log('‚úÖ Landscape orientation');\n}\n\n// ===== MODEL SELECTION =====\nif (isFluxLogo && fluxModels.length > 0) {\n  model = fluxModels[0];\n  modelType = 'Flux';\n  console.log('‚úÖ Flux logo mode');\n} else if (isCartoon) {\n  model = sd15Models[0];\n  selectedVae = animeVae;\n  quality.cfg = 11.0;\n  console.log('‚úÖ Cartoon/Anime mode');\n} else if ((lowerOriginal.includes('photo') || lowerOriginal.includes('realistic')) && modelType !== 'SDXL') {\n  // Use Realistic Vision for 512x512 photorealistic\n  const realisticModel = sd15Models.find(m => m.includes('realisticVision'));\n  if (realisticModel) {\n    model = realisticModel;\n    quality.cfg = 7.0;\n    quality.steps = 35;\n    console.log('‚úÖ Using Realistic Vision for photorealism');\n  }\n}\n\n// Quick/Fast mode\nif (lowerOriginal.includes('quick') || lowerOriginal.includes('fast')) {\n  const lightningModel = sdxlModels.find(m => m.toLowerCase().includes('lightning'));\n  if (lightningModel) {\n    model = lightningModel;\n    modelType = 'SDXL';\n    quality.steps = 8;\n    quality.cfg = 2.0;\n    quality.sampler = 'dpmpp_sde';\n    dimensions = { width: 1024, height: 1024, desc: '1024x1024 (Quick)' };\n    console.log('‚ö° Quick mode ‚Üí Using Lightning:', model);\n  }\n}\n\n// Safety check\nif (!model || model.toLowerCase().includes('inpaint')) {\n  model = 'dreamshaper_8.safetensors';\n  console.log('‚ö†Ô∏è Model fallback to DreamShaper');\n}\n\nconsole.log('üé® Final config:');\nconsole.log('- Model:', model);\nconsole.log('- Type:', modelType);\nconsole.log('- Dimensions:', dimensions.desc);\nconsole.log('- Steps:', quality.steps);\nconsole.log('- CFG:', quality.cfg);\n\n// ===== SEED =====\nconst seed = Math.floor(Math.random() * 999999);\n\n// ===== BUILD WORKFLOW =====\nconst workflow = {\n  prompt: {\n    \"4\": { inputs: { ckpt_name: model }, class_type: \"CheckpointLoaderSimple\" },\n    \"5\": { inputs: { width: dimensions.width, height: dimensions.height, batch_size: 1 }, class_type: \"EmptyLatentImage\" },\n    \"6\": { inputs: { text: positive, clip: [\"4\", 1] }, class_type: \"CLIPTextEncode\" },\n    \"7\": { inputs: { text: negative, clip: [\"4\", 1] }, class_type: \"CLIPTextEncode\" },\n    \"3\": { inputs: { seed, steps: quality.steps, cfg: quality.cfg, sampler_name: quality.sampler, scheduler: quality.scheduler, positive: [\"6\", 0], negative: [\"7\", 0], latent_image: [\"5\", 0], model: [\"4\", 0], denoise: 1.0 }, class_type: \"KSampler\" },\n    \"8\": { inputs: { samples: [\"3\", 0], vae: [\"4\", 2] }, class_type: \"VAEDecode\" },\n    \"9\": { inputs: { filename_prefix: \"ai_generated_\", images: [\"8\", 0] }, class_type: \"SaveImage\" }\n  },\n  client_id: \"n8n\",\n  metadata: { \n    seed, \n    dimensions: dimensions.desc, \n    steps: quality.steps, \n    cfg: quality.cfg, \n    sampler: quality.sampler, \n    scheduler: quality.scheduler, \n    model, \n    model_type: modelType, \n    vae: selectedVae, \n    style: isCartoon ? 'cartoon' : (isLogo ? 'logo' : 'photorealistic'),\n    positive_preview: positive.substring(0, 100),\n    negative_preview: negative.substring(0, 50),\n    original_request: originalUserInput.substring(0, 100)\n  }\n};\n\n// ===== LORAS (FOR LOGOS) =====\nconst selectedLoras = [];\nif (isLogo) {\n  const logoLoras = allLoras.filter(l => \n    l.includes('Harrlogos') || \n    l.includes('texta') || \n    l.includes('LogoRedmond')\n  );\n  \n  if (logoLoras.length > 0) {\n    selectedLoras.push({ \n      name: logoLoras[0], \n      strength_model: 0.75, \n      strength_clip: 0.0 \n    });\n    console.log('‚úÖ Added logo LoRA:', logoLoras[0]);\n  }\n}\n\nif (selectedLoras.length > 0) {\n  let lastModelRef = [\"4\", 0];\n  let nodeId = 10;\n  \n  selectedLoras.forEach(l => {\n    const id = String(nodeId);\n    workflow.prompt[id] = {\n      class_type: \"LoraLoader\",\n      inputs: { \n        lora_name: l.name, \n        strength_model: l.strength_model, \n        strength_clip: l.strength_clip, \n        strength_alpha: 1.0, \n        model: lastModelRef, \n        clip: [\"4\", 1] \n      }\n    };\n    lastModelRef = [id, 0];\n    nodeId++;\n  });\n  \n  workflow.prompt[\"3\"].inputs.model = lastModelRef;\n}\n\nreturn [{ json: workflow }];"
      },
      "id": "c8ba7a34-4e25-48fe-90e4-c80e53f79f1b",
      "name": "Build ComfyUI Workflow",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1280,
        -32
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://host.docker.internal:8188/prompt",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "application/json",
        "body": "={{ JSON.stringify($json) }}",
        "options": {}
      },
      "id": "1b6d1e55-66f4-41d3-9f89-4fa479298458",
      "name": "POST to ComfyUI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        768,
        208
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "1",
              "name": "promptId",
              "type": "string",
              "value": "={{ $json.prompt_id }}"
            },
            {
              "id": "2",
              "name": "metadata",
              "type": "object",
              "value": "={{ $('Build ComfyUI Workflow').item.json.metadata }}"
            },
            {
              "id": "3",
              "name": "startTime",
              "type": "number",
              "value": "={{ Date.now() }}"
            },
            {
              "id": "4",
              "name": "attempt",
              "type": "number",
              "value": "=0"
            }
          ]
        },
        "options": {}
      },
      "id": "ac84aa6a-07e4-426c-8171-3b711aa3d09c",
      "name": "Store Polling Data",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        976,
        208
      ]
    },
    {
      "parameters": {
        "url": "=http://host.docker.internal:8188/history/{{ $json.promptId }}",
        "options": {}
      },
      "id": "6c5abd1f-02e7-418e-a014-c68a40817875",
      "name": "Check History",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1168,
        208
      ]
    },
    {
      "parameters": {
        "jsCode": "const promptId = $('Store Polling Data').item.json.promptId;\nconst attempt = $('Store Polling Data').item.json.attempt;\nconst startTime = $('Store Polling Data').item.json.startTime;\nconst metadata = $('Store Polling Data').item.json.metadata;\nconst historyData = $input.item.json;\n\nif (historyData[promptId]?.outputs?.['9']) {\n  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);\n  console.log(`‚úÖ Complete! Time: ${elapsed}s, Checks: ${attempt + 1}`);\n  return [{ json: { status: 'completed', promptId, outputs: historyData[promptId].outputs['9'], totalTime: parseFloat(elapsed), attempts: attempt + 1, metadata } }];\n}\n\nconst elapsed = ((Date.now() - startTime) / 1000).toFixed(1);\nconsole.log(`[${elapsed}s] Check ${attempt + 1}: üé® Processing...`);\nreturn [{ json: { status: 'pending', promptId, attempt: attempt + 1, startTime, metadata } }];"
      },
      "id": "76df4ead-b2e6-46e0-a953-99a247ee6eeb",
      "name": "Parse Status",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1376,
        208
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "typeValidation": "loose"
          },
          "conditions": [
            {
              "id": "c1",
              "leftValue": "={{ $json.status }}",
              "rightValue": "completed",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            },
            {
              "id": "c2",
              "leftValue": "={{ $json.attempt }}",
              "rightValue": 150,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "841107cc-b55f-4549-b68e-067fb7062f38",
      "name": "Is Complete?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1568,
        208
      ]
    },
    {
      "parameters": {
        "amount": 2
      },
      "id": "f08767a6-cdc8-4f00-8457-6d8091bce93c",
      "name": "Wait 2s",
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        1424,
        432
      ],
      "webhookId": "wait-webhook-id"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "1",
              "name": "promptId",
              "type": "string",
              "value": "={{ $json.promptId }}"
            },
            {
              "id": "2",
              "name": "attempt",
              "type": "number",
              "value": "={{ $json.attempt }}"
            },
            {
              "id": "3",
              "name": "startTime",
              "type": "number",
              "value": "={{ $json.startTime }}"
            },
            {
              "id": "4",
              "name": "metadata",
              "type": "object",
              "value": "={{ $json.metadata }}"
            }
          ]
        },
        "options": {}
      },
      "id": "d7c971e4-f1b3-49bc-a785-23ffcf128607",
      "name": "Loop Back",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1776,
        352
      ]
    },
    {
      "parameters": {
        "jsCode": "const status = $input.item.json.status;\nconst outputs = $input.item.json.outputs;\nconst attempt = $input.item.json.attempt;\n\nif (status === 'completed' && outputs?.images?.[0]) {\n  const img = outputs.images[0];\n  return [{ json: { filename: img.filename, subfolder: img.subfolder || '', type: img.type, metadata: $input.item.json.metadata } }];\n}\n\nthrow new Error(`Generation timed out after ${attempt} attempts (${attempt * 2} seconds)`);"
      },
      "id": "798ed807-5292-4e4a-90a3-8d749c4ad28d",
      "name": "Extract Image Info",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1776,
        208
      ]
    },
    {
      "parameters": {
        "url": "=http://host.docker.internal:8188/view?filename={{ $json.filename }}&subfolder={{ $json.subfolder }}&type={{ $json.type }}",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          }
        }
      },
      "id": "c4d656e3-0d96-48bc-9587-5df247782feb",
      "name": "Download Image",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1968,
        208
      ]
    },
    {
      "parameters": {
        "jsCode": "const metadata = $('Extract Image Info').item.json.metadata;\nconst filename = $('Extract Image Info').item.json.filename;\nconst imageUrl = `http://127.0.0.1:8188/view?filename=${filename}&type=output`;\n\nconst loraLine = metadata.loras?.length > 0 ? `- LoRAs: ${metadata.loras.join(', ')}\\n` : '';\nconst vaeLine = metadata.vae ? `- VAE: ${metadata.vae}\\n` : '';\nconst aspectLine = metadata.dimensions ? `- Dimensions: ${metadata.dimensions}\\n` : '';\nconst presetLine = metadata.preset ? `- Preset: ${metadata.preset}\\n` : '';\nconst styleLine = metadata.style ? `- Style: ${metadata.style}\\n` : '';\n\nconst message = `‚ú® **Image Generated Successfully!**\\n\\n![Generated Image](${imageUrl})\\n\\n**Filename:** ${filename}\\n\\n**Settings:**\\n${aspectLine}- Steps: ${metadata.steps}\\n- CFG: ${metadata.cfg}\\n- Sampler: ${metadata.sampler}\\n- Scheduler: ${metadata.scheduler}\\n- Model: ${metadata.model}\\n${vaeLine}${loraLine}${presetLine}${styleLine}- Seed: ${metadata.seed}\\n\\nüé® Your AI-generated image is ready!`;\n\nreturn [{ json: { output: message } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2176,
        208
      ],
      "id": "6e7538ac-de8a-416e-86d2-4c2a4071408e",
      "name": "Format Image Output"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a helpful AI assistant.\n\n{{ $json.conversationHistory && $json.conversationHistory.length > 0 ? \"Recent conversation:\\n\" + $json.conversationHistory.map((msg, i) => (msg.role === 'user' ? 'User' : 'Assistant') + ': ' + msg.content).join('\\n') + \"\\n\\n\" : \"\" }}Current question: {{ $json.chatInput }}\n\nPlease respond to the current question."
      },
      "id": "42b98bb9-241e-40a1-be48-159220d6c1ae",
      "name": "Regular Chat",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        80,
        480
      ]
    },
    {
      "parameters": {
        "model": "qwen2.5:latest",
        "options": {}
      },
      "id": "995f7de8-9529-43d6-a8cb-2b7728ea0bc3",
      "name": "Ollama Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmOllama",
      "typeVersion": 1,
      "position": [
        160,
        640
      ],
      "credentials": {
        "ollamaApi": {
          "id": "xHuYe0MDGOs9IpBW",
          "name": "Local Ollama service"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "1",
              "name": "text",
              "type": "string",
              "value": "={{ $json.text }}"
            }
          ]
        },
        "options": {}
      },
      "id": "37d1859b-a831-40e6-99f4-2b7b969036db",
      "name": "Format Chat Output",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        368,
        352
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "={{ $json.text || $json.output }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.5,
      "position": [
        688,
        -64
      ],
      "id": "a9e471a2-9bc7-495e-bd78-4c537b8dcb2b",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "url": "http://192.168.50.202:8188/models/vae",
        "options": {
          "response": {
            "response": {
              "neverError": true,
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        864,
        -240
      ],
      "id": "4d7d635c-871c-445f-956a-cfc5ab010fdd",
      "name": "Get VAEs"
    },
    {
      "parameters": {
        "url": "http://192.168.50.202:8188/models/loras",
        "options": {
          "response": {
            "response": {
              "neverError": true,
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        864,
        -432
      ],
      "id": "8c1041f3-8efc-482a-8bf7-ec838e898966",
      "name": "Get LoRAs"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    checkpoints: $items(\"Wrap Checkpoints\")[0].json.list,\n    vae: $items(\"Wrap VAEs\")[0].json.list,\n    loras: $items(\"Wrap LoRAs\")[0].json.list\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1392,
        -384
      ],
      "id": "1b04d8cc-cd4d-4215-81ca-51fa8eb3a3a4",
      "name": "Combine Model Lists"
    },
    {
      "parameters": {
        "url": "http://192.168.50.202:8188/models/checkpoints",
        "options": {
          "response": {
            "response": {
              "neverError": true,
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        864,
        -80
      ],
      "id": "39eee3f2-252b-44e3-8949-c1d166733c2b",
      "name": "Get Checkpoints"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    list: $input.all().map(i => i.json)\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1024,
        -96
      ],
      "id": "aa56e966-664b-4948-b308-8ef609d44fbc",
      "name": "Wrap Checkpoints"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    list: $input.all().map(i => i.json)\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1024,
        -240
      ],
      "id": "044805d6-8ca9-4a12-98a8-c8947aa471a1",
      "name": "Wrap VAEs"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    list: $input.all().map(i => i.json)\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1024,
        -416
      ],
      "id": "624002de-1cf1-4c17-9db9-7ee51c4b0790",
      "name": "Wrap LoRAs"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {
          "clashHandling": {
            "values": {
              "resolveClash": "addSuffix"
            }
          }
        }
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        1808,
        -224
      ],
      "id": "a974d2b5-99d6-4ea9-9cef-cd5be051538f",
      "name": "Merge"
    },
    {
      "parameters": {
        "jsCode": "// Save the original chatInput for later use\nconst originalInput = $json.chatInput || '';\n\nconsole.log('üíæ Saving original input:', originalInput.substring(0, 100));\n\nreturn [{\n  json: {\n    ...$json,\n    originalChatInput: originalInput\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -80,
        384
      ],
      "id": "f5e59e92-f6c4-49db-9377-483b19c7b7ce",
      "name": "Save Original Input"
    }
  ],
  "pinData": {},
  "connections": {
    "Chat Trigger": {
      "main": [
        [
          {
            "node": "Check Attachments",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Attachments": {
      "main": [
        [
          {
            "node": "Has Images?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Images?": {
      "main": [
        [
          {
            "node": "Prepare Vision",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Contains 'image'?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Vision": {
      "main": [
        [
          {
            "node": "Llava Direct API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Llava Direct API": {
      "main": [
        [
          {
            "node": "Format Vision Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Vision Output": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Contains 'image'?": {
      "main": [
        [
          {
            "node": "Save Original Input",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Regular Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Engineer": {
      "main": [
        [
          {
            "node": "Parse Prompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Engineer": {
      "ai_languageModel": [
        [
          {
            "node": "AI Engineer",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Parse Prompts": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          },
          {
            "node": "Get Checkpoints",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build ComfyUI Workflow": {
      "main": [
        [
          {
            "node": "POST to ComfyUI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "POST to ComfyUI": {
      "main": [
        [
          {
            "node": "Store Polling Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Polling Data": {
      "main": [
        [
          {
            "node": "Check History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check History": {
      "main": [
        [
          {
            "node": "Parse Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Status": {
      "main": [
        [
          {
            "node": "Is Complete?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Complete?": {
      "main": [
        [
          {
            "node": "Extract Image Info",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait 2s",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait 2s": {
      "main": [
        [
          {
            "node": "Loop Back",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Back": {
      "main": [
        [
          {
            "node": "Check History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Image Info": {
      "main": [
        [
          {
            "node": "Download Image",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Image": {
      "main": [
        [
          {
            "node": "Format Image Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Image Output": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Regular Chat": {
      "main": [
        [
          {
            "node": "Format Chat Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Regular Chat",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Format Chat Output": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get LoRAs": {
      "main": [
        [
          {
            "node": "Wrap LoRAs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get VAEs": {
      "main": [
        [
          {
            "node": "Wrap VAEs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine Model Lists": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Get Checkpoints": {
      "main": [
        [
          {
            "node": "Wrap Checkpoints",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wrap VAEs": {
      "main": [
        [
          {
            "node": "Get LoRAs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wrap Checkpoints": {
      "main": [
        [
          {
            "node": "Get VAEs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wrap LoRAs": {
      "main": [
        [
          {
            "node": "Combine Model Lists",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Build ComfyUI Workflow",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Original Input": {
      "main": [
        [
          {
            "node": "AI Engineer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "availableInMCP": false
  },
  "versionId": "b0585783-5f66-4bf4-95df-c5277a9dba6b",
  "meta": {
    "instanceId": "558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a"
  },
  "id": "7l86HYaBVOM7O9sB",
  "tags": []
}